{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notas sobre modificaciones realizadas 2024-05-11:\n",
    "- Se filtro `df_business`, donde col `is_open == 1` (ver notas explicativas en el block de codigo)\n",
    "- En `df_business`, no se elimina la col `address` porque puede ser dato util para enlazar al dataset de Google\n",
    "- En `df_attributes`, se fijo col `business_id` como el index, para su uso eficiente en BigQuery\n",
    "- En `df_attributes`, col `attributes` se mantendra anidado al exportar a BigQuery (BQ maneja datos anidados con mas eficiencia vs. tener una columna por atributo)\n",
    "- `df_checkin` se desanido usando metodo `explode()`, y se filtro por los `business_id` que estan en el `df_business` procesado\n",
    "- Nota: en `df_user`, hay `user_id` repetidos!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from ftfy import fix_text\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opción que deshabilita el limite de columnas y filas mostradas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Carga de data Yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path de los archivos no-procesados (formato parquet)\n",
    "path_data = '../../data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `y-business.parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_business = pd.read_parquet(f'{path_data}/raw/y-business.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `y-checkin.parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_checkin = pd.read_parquet(f'{path_data}/raw/y-checkin.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `y-tip.parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tip = pd.read_parquet(f'{path_data}/raw/y-tip.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `y-review.parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../data/raw/y-review/y-review_03.parquet',\n",
       " '../../data/raw/y-review/y-review_02.parquet',\n",
       " '../../data/raw/y-review/y-review_01.parquet']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear lista de archivos en /data/raw/y-review/\n",
    "review_parquets = glob(f'{path_data}/raw/y-review/*')\n",
    "review_parquets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear dataframe donde se unen los datos extraidos de parquet\n",
    "df_review = pd.DataFrame()\n",
    "# Iterar por cada parquet dentro de /data/raw/y-review/\n",
    "for p in review_parquets:\n",
    "    # Leer parquet\n",
    "    df = pd.read_parquet(p)\n",
    "    # Unir a df_review\n",
    "    df_review = pd.concat([df_review, df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review['date'].isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `y-user.parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear lista de archivos en /data/raw/y-user/\n",
    "user_parquets = glob(f'{path_data}/raw/y-user/*')\n",
    "user_parquets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear dataframe donde se unen los datos extraidos de parquet\n",
    "df_user = pd.DataFrame()\n",
    "# Iterar por cada parquet dentro de /data/raw/y-user/\n",
    "for p in user_parquets:\n",
    "    # Leer parquet\n",
    "    df = pd.read_parquet(p)\n",
    "    # Unir a df_user\n",
    "    df_user = pd.concat([df_user, df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## Análisis Exploratorio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### `df_business`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisar el dataset e imprimir las primeras filas\n",
    "print(df_business.info())\n",
    "df_business.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columna `is_open`: filtro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta columna inidca el estado operacional del negocio. Se filtra negocios que estan operando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_open\n",
       "1    119702\n",
       "0     30649\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_business['is_open'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_open\n",
       "1    119702\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_business = df_business[df_business['is_open'] == 1]\n",
    "df_business['is_open'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columna `categories`: typecasting y filtro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir columna 'categories' a tipo list\n",
    "df_business['categories'] = df_business['categories'].apply(lambda x: x.replace(', ',',').split(',') if x else [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34987, 14)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dejar en el dataset solo la categoría 'Restaurants'\n",
    "filtro_categoria = 'Restaurants'\n",
    "df_business = df_business[df_business['categories'].apply(lambda x: filtro_categoria in x)]\n",
    "df_business.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtro por estados 'DE', 'NJ', 'PA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10203, 14)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtramos los datos a la región elegida\n",
    "estados_filtro = ['DE', 'NJ', 'PA']\n",
    "df_business = df_business[df_business['state'].isin(estados_filtro)]\n",
    "df_business.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisar los datos nuevamente\n",
    "df_business.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solo tenemos algunos nulos en \"attributes\" y \"hours\", que por el momento no se van a rellenar, hasta decidir si estas columnas serán utilizadas para los análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisar las columnas numéricas\n",
    "df_business.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No se observan valores erróneos, como latitud y longitud con signo invertido, o calificaciones fuera del intérvalo 1 a 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por el momento se va a mantener como está, hasta decidir si alguna de las \"keys\" puede ser de utilidad para algún análisis, y en ese caso se prodecerá a desanidar los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisar nombres de columnas\n",
    "df_business.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Las siguientes columnas serán eliminadas:\n",
    "\n",
    "addres: Se cuenta con los datos de latitud y longitud  \n",
    "is_open: Se entiende que se refiere al momento de la extracción de los datos. Se cuenta con los horarios de apertura y cierre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar las columnas antes mencionadas\n",
    "#df_business.drop(\"address\", axis=1, inplace=True)  # se mantiene para comparar con dataset Google\n",
    "df_business.drop(\"is_open\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SE VA A EXTRAER A UN NUEVO ARCHIVO EL CONTENIDO DE LA COLUMNA \"attributes\", y se va a eliminar la misma del dataset de \"business\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un dataframe nuevo para los atributos\n",
    "df_attributes = df_business[[\"business_id\", \"attributes\"]]\n",
    "# Drop a \"attributes\" del df de origen\n",
    "df_business.drop(\"attributes\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fijar `business_id`` como el index de `df_business`\n",
    "df_business.set_index(\"business_id\", inplace=True)\n",
    "# Fijar `business_id`` como el index de `df_attributes`\n",
    "df_attributes.set_index(\"business_id\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscar la primera fila que tenga atributos y extraer el diccionario para usar las llaves en la creación de las columnas del dataframe\n",
    "contador = 0\n",
    "total = df_attributes.shape[0]\n",
    "while contador < total:\n",
    "    if type(df_attributes[\"attributes\"][contador]) != dict:\n",
    "        pass\n",
    "    else:\n",
    "        diccionario = df_attributes[\"attributes\"][contador]\n",
    "        break\n",
    "\n",
    "    contador +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in diccionario.keys():\n",
    "    df_attributes[key] = \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contador = 0\n",
    "total = df_attributes.shape[0]\n",
    "while contador < total:\n",
    "    if type(df_attributes[\"attributes\"][contador]) != dict:\n",
    "        pass\n",
    "    else:\n",
    "        dicc = df_attributes[\"attributes\"][contador]\n",
    "        for key in dicc.keys():\n",
    "            df_attributes[key][contador] = dicc[key][0]\n",
    "\n",
    "    contador +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exportacion datos limpios de Business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_business.to_parquet(f'{path_data}/y_business_CLEAN.parquet')\n",
    "df_attributes.to_parquet(f'{path_data}/y_business_attrib_CLEAN.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### `df_checkin`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### En principio no vamos a realizar análisis que incluyan la fecha y hora de ingreso de los usuarios al local. Este dataset no se va a utilizar, por lo que no se va a desanidar la columna de registros (date), ni se va a realizar ningún otro proceso sobre el mismo. Se observa de todos modos que el dataset no contiene valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisar el dataset\n",
    "print(df_checkin.info())\n",
    "df_checkin.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flitramos por los `business_id` en `df_business` procesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtro_id = df_business['business_id']\n",
    "df_checkin = df_checkin[df_checkin['business_id'].isin(filtro_id)]\n",
    "df_checkin.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se desanida usando metodo `explode()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_checkin.set_index('business_id', inplace=True)\n",
    "df_checkin['date'] = df_checkin['date'].str.split(',')\n",
    "df_checkin = df_checkin.explode('date')\n",
    "df_checkin['date'] = pd.to_datetime(df_checkin['date'], format='mixed')\n",
    "df_checkin.reset_index(inplace=True)\n",
    "df_checkin.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exportacion datos limpios de CheckIn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_checkin.to_parquet(f'{path_data}/y_checkin_CLEAN.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### `df_tip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisar el dataset\n",
    "print(df_tip.info())\n",
    "df_tip.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tip.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos no contienen nulos y están en el formato correcto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sacar los id de los locales elegidos en el dataset de Business\n",
    "filtro_id = df_business[\"business_id\"]\n",
    "# Filtrar los tips\n",
    "df_tip = df_tip[df_tip[\"business_id\"].isin(filtro_id)]\n",
    "df_tip.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exportacion datos limpios de Tip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tip.to_parquet(f'{path_data}/y_tip_CLEAN.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### `df_review`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6990280, 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1138498, 9)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sacar los id de los locales elegidos en el dataset de Business\n",
    "filtro_id = df_business[\"business_id\"]\n",
    "# Filtrar los review\n",
    "df_review = df_review[df_review[\"business_id\"].isin(filtro_id)]\n",
    "df_review.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_review.iloc[0]['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Typecasting de col `date`\n",
    "df_review['date'] = pd.to_datetime(df_review['date'], format='mixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrigir errores de decoding de texto, columna `text`\n",
    "df_review['text'] = df_review['text'].apply(fix_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar col `name`, desde `df_business`\n",
    "df_review = pd.merge(df_review, df_business[['business_id', 'name']], on='business_id', how='left')\n",
    "\n",
    "# Fijar nueva columna `name` como la primer columna del df \n",
    "nom_col = df_review.pop('name')\n",
    "df_review.insert(0, 'name', nom_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review['review_id'].duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>olnOvUh4NQbGohritme22Q</th>\n",
       "      <td>Grand Hacienda</td>\n",
       "      <td>X3ZthrdL_nsKhR9C2VbTZA</td>\n",
       "      <td>EF5Fpofz71Fo_UqUpZUYBQ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A piss-poor, inauthentic sodium bomb. Must get...</td>\n",
       "      <td>2019-05-28 02:03:58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  name                 user_id  \\\n",
       "review_id                                                        \n",
       "olnOvUh4NQbGohritme22Q  Grand Hacienda  X3ZthrdL_nsKhR9C2VbTZA   \n",
       "\n",
       "                                   business_id  stars  useful  funny  cool  \\\n",
       "review_id                                                                    \n",
       "olnOvUh4NQbGohritme22Q  EF5Fpofz71Fo_UqUpZUYBQ    1.0       0      0     0   \n",
       "\n",
       "                                                                     text  \\\n",
       "review_id                                                                   \n",
       "olnOvUh4NQbGohritme22Q  A piss-poor, inauthentic sodium bomb. Must get...   \n",
       "\n",
       "                                      date  \n",
       "review_id                                   \n",
       "olnOvUh4NQbGohritme22Q 2019-05-28 02:03:58  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review.set_index('review_id', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exportacion datos limpios de Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review.to_parquet(f'{path_data}/y_review_CLEAN.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploracion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('las columnas de business son:', df_business.columns)\n",
    "print('las columnas de checkin son:', df_checkin.columns)\n",
    "print('las columnas de tip son:', df_tip.columns)\n",
    "print('las columnas de user son:', df_user.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review_filtrado = pd.read_parquet(r'/home/henry/PF/Henry_PF/data/raw/y-review_filtrado.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('las columnas de review_filtrado son:', df_review_filtrado.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "corroboramos la información de la columna state en las reviews de yelp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review_filtrado['state'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se desea analizar la puntuación en estrellas por estado: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar por estado y puntuación de estrellas, y contar el número de reseñas\n",
    "reseñas_por_estado = df_review_filtrado.groupby(['state', 'stars']).size().unstack(fill_value=0)\n",
    "\n",
    "# Crear un gráfico de barras para visualizar las reseñas por estado y puntuación de estrellas\n",
    "reseñas_por_estado.plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('Cantidad de Reseñas por Puntuación de Estrellas y Estado')\n",
    "plt.xlabel('Estado')\n",
    "plt.ylabel('Cantidad de Reseñas')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Puntuación de Estrellas')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtramos los restaurants de la cadena Darden en el DataFrame de business:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombres específicos a buscar\n",
    "nombres_especificos = [\n",
    "    'olive garden', 'longhorn steakhouse', 'yard house', \n",
    "    \"ruth's chris steak house\", \"cheddar's scratch kitchen\", \n",
    "    'the capital grille', 'seasons 52', \"eddiev's\", \n",
    "    'bahama breeze'\n",
    "]\n",
    "\n",
    "# Convertir los nombres a minúsculas para hacer la búsqueda insensible a mayúsculas y minúsculas\n",
    "nombres_especificos = [nombre.lower() for nombre in nombres_especificos]\n",
    "\n",
    "# Filtrar el DataFrame por los nombres específicos\n",
    "df_filtrado_nombres = df_business[df_business['name'].str.lower().str.contains('|'.join(nombres_especificos), case=False)]\n",
    "\n",
    "df_filtrado_nombres.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar la cantidad de negocios para cada nombre específico\n",
    "conteo_por_nombre = df_filtrado_nombres['name'].value_counts()\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(conteo_por_nombre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir los nombres a minúsculas para hacer la búsqueda insensible a mayúsculas y minúsculas\n",
    "nombres_especificos = [nombre.lower() for nombre in nombres_especificos]\n",
    "\n",
    "# Filtrar el DataFrame por los nombres específicos\n",
    "df_filtrado_nombres = df_business[df_business['name'].str.lower().isin(nombres_especificos)]\n",
    "\n",
    "# Agrupar por nombre, asumiendo que cada nombre tiene asociadas las mismas categorías\n",
    "categorias_por_nombre = df_filtrado_nombres.groupby('name')['categories'].unique().reset_index()\n",
    "\n",
    "# Mostrar los resultados de manera más legible\n",
    "categorias_por_nombre\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### `df_user`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar usuarios con reviews en los business de interes\n",
    "filtro_users = df_review['user_id']\n",
    "# Filtrar los review\n",
    "df_user = df_user[df_user[\"user_id\"].isin(filtro_users)]\n",
    "df_user.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se descartar col `name`\n",
    "df_user.drop('name', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typecasting de col `yelping_since`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Typecasting de col `date`\n",
    "df_user['yelping_since'] = pd.to_datetime(df_user['yelping_since'], format='mixed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typecasting de col `friends`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir columna 'friends' a tipo list\n",
    "df_user['friends'] = df_user['friends'].apply(lambda x: x.replace(', ',',').split(',') if x != 'None' else [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user['user_id'].duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Existen duplicados user_id. No se puede fijar como index\n",
    "#df_user.set_index('user_id', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exportacion datos limpios de User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user.to_parquet(f'{path_data}/y_user_CLEAN.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploracion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar se descartan las columnas de cumplidos hacia los usuarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_filtrado = df_user[['user_id','name', 'review_count', 'yelping_since',\n",
    "       'useful', 'funny', 'cool', 'elite', 'friends', 'fans', 'average_stars']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se determinara si se tiene pasajeros sospechosos que con una cantidad apreciable de reseñas siempre puntuen con 5 o 1 estrella, que solo hayan hecho una reseña o que presenten nombres extraños. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Condiciones de usuarios sospechosos\n",
    "mask_1 = (df_user_filtrado.average_stars == 5) & (df_user_filtrado.review_count > 4)\n",
    "mask_2 = (df_user_filtrado.average_stars == 1) & (df_user_filtrado.review_count > 4) # Estas dos primeras condiciones son para evitar reseñas fuertemente sesgadas positiva o negativamente\n",
    "mask_3 = (df_user_filtrado.review_count == 1) #No se tomaran en cuenta usuarios que hayan escrito una unica reseña\n",
    "mask_4 = (df_user_filtrado.name.str.len() <= 2) | df_user_filtrado.name.str.contains('\\.')#Esto es para filtrar nombres extraños como los que presentan 1 o 2 letras o los que contienen puntos\n",
    "\n",
    "#Se define un nuevo df sin los usuarios sospechosos\n",
    "df_user_filtrado = df_user_filtrado[~(mask_1) & ~(mask_2) & ~(mask_3) & ~(mask_4)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cantidad de usuarios luego de filtrar:\", len(df_user_filtrado))\n",
    "print(\"Cantidad de usuarios totales:\", len(df_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuacion se  analizan las reviews de los usuario considerados como elite en algun año."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_elite = df_user_filtrado[(df_user_filtrado.elite.notna()) & (df_user_filtrado.elite != \"\" )]\n",
    "print(\"Cantidad de usuarios elite:\", len(df_user_elite))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_filtrado[[\"review_count\",\"average_stars\"]].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_elite[[\"review_count\",\"average_stars\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,5))\n",
    "\n",
    "\n",
    "ax1.hist(df_user_filtrado.average_stars)\n",
    "ax1.set_title('Histograma de puntuacion de los usuarios')\n",
    "ax1.set_xlabel('Calificación Promedio')\n",
    "ax1.set_ylabel('Numero de usuarios')\n",
    "\n",
    "\n",
    "ax2.hist(df_user_elite.average_stars)\n",
    "ax2.set_title('Usuarios de puntuacion de los usuarios elite')\n",
    "ax2.set_xlabel('Calificación Promedio')\n",
    "ax2.set_ylabel('Numero de usuarios')\n",
    "\n",
    "# Ajustar diseño\n",
    "plt.tight_layout()\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ambas distribuciones se encuentran sesgadas a la izquierda, sin embargo la del promedio de las puntuaciones de los usuarios elite se asemeja mucho mas a una distribucion normal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contar_amigos(friends):\n",
    "    if friends == \"None\":\n",
    "        return 0\n",
    "    else:\n",
    "        return len(friends.split(','))\n",
    "\n",
    "df_user_elite['num_friends'] = df_user_elite['friends'].apply(contar_amigos)\n",
    "df_user_filtrado['num_friends'] = df_user_filtrado['friends'].apply(contar_amigos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tambien es importante destacar que estos usuarios son mas influyentes, ya que presentan una mayor cantidad de fans y amigos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una figura y ejes para los subgráficos\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "# Graficar el primer histograma en el primer subgráfico\n",
    "axs[0, 0].hist(df_user_filtrado[df_user_filtrado.num_friends < 2000].num_friends)\n",
    "axs[0, 0].set_title('Histograma del numero de amigos por usuario')\n",
    "axs[0, 0].set_xlabel('Número de amigos')\n",
    "axs[0, 0].set_ylabel('Número de usuarios')\n",
    "\n",
    "# Graficar el segundo histograma en el segundo subgráfico\n",
    "axs[0, 1].hist(df_user_elite[df_user_elite.num_friends < 2000].num_friends)\n",
    "axs[0, 1].set_title('Histograma del numero de amigos por usuario elite')\n",
    "axs[0, 1].set_xlabel('Número de amigos')\n",
    "axs[0, 1].set_ylabel('Número de usuarios')\n",
    "\n",
    "# Graficar el tercer histograma en el tercer subgráfico\n",
    "axs[1, 0].hist(df_user_elite[df_user_elite.fans < 300].fans)\n",
    "axs[1, 0].set_title('Histograma del numero de fans por usuario elite')\n",
    "axs[1, 0].set_xlabel('Número de fans')\n",
    "axs[1, 0].set_ylabel('Número de usuarios')\n",
    "\n",
    "# Graficar el cuarto histograma en el cuarto subgráfico\n",
    "axs[1, 1].hist(df_user_filtrado[df_user_filtrado.fans < 300].fans)\n",
    "axs[1, 1].set_title('Histograma del numero de fans por usuario')\n",
    "axs[1, 1].set_xlabel('Número de fans')\n",
    "axs[1, 1].set_ylabel('Número de usuarios')\n",
    "\n",
    "# Ajustar espaciado entre subgráficos\n",
    "plt.tight_layout()\n",
    "\n",
    "# Mostrar la figura\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## Mapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_business.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_plot_mapa(df: pd.DataFrame) -> plt.Figure:\n",
    "    \"\"\"Devuelve una grafica tipo plt.Figure, con un Shapefile que\n",
    "    presenta el territorio de USA, y el dataframe de entrada con\n",
    "    columnas de coordinadas ('longitude', 'latitude').\n",
    "    \"\"\"\n",
    "    # Descartar los nulos\n",
    "    df = df.dropna(axis=0, subset=['longitude', 'latitude'])\n",
    "\n",
    "    # Crear un GeoDataFrame con la data de coordinadas\n",
    "    geometry = [Point(xy) for xy in zip(df['longitude'], df['latitude'])]\n",
    "    gdf = GeoDataFrame(df, geometry=geometry)\n",
    "\n",
    "    # Cargar archivo shapefile\n",
    "    mapa = gpd.read_file('../assets/map_state_5m.shp')\n",
    "\n",
    "    # Calculamos los limites del mapa\n",
    "    minx, miny, maxx, maxy = gdf.total_bounds\n",
    "\n",
    "    # Creamos los plots del mapa\n",
    "    plt.figure()  # limpiar memory de plotly\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    mapa.plot(ax=ax, color='white', edgecolor='black')\n",
    "    gdf.plot(ax=ax, marker='o', color='red', markersize=.001)\n",
    "\n",
    "    # Calculamos el margen del grafico\n",
    "    margin_ratio = 0.2\n",
    "    marginx = (maxx - minx) * margin_ratio\n",
    "    marginy = (maxy - miny) * margin_ratio\n",
    "    # Aplicamos los margenes en relacion a los plots en los extremos\n",
    "    ax.set_xlim(minx - marginx, maxx + marginx)\n",
    "    ax.set_ylim(miny - marginy, maxy + marginy)\n",
    "\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapa_business = crear_plot_mapa(df_business)\n",
    "mapa_business.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapa: area metro Philadelphia (PA, NJ, DE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar area geografica de interes\n",
    "estados = ['PA', 'NJ', 'DE']\n",
    "\n",
    "df_estados = df_business[df_business['state'].isin(estados)]\n",
    "df_estados['state'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_estados.shape  # expected value: (44842, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"     !!  No devuelve output esperado (mapa no se filtra)\n",
    "\n",
    "\n",
    "df = df_estados\n",
    "\n",
    "# Descartar nulos\n",
    "#df = df_estados.dropna(axis=0, subset=['longitude', 'latitude'])\n",
    "\n",
    "# Crear un GeoDataFrame con la data de coordinadas\n",
    "\n",
    "geo = [Point(xy) for xy in zip(df['longitude'], df['latitude'])]\n",
    "gdf = GeoDataFrame(df, geometry=geo)\n",
    "\n",
    "# Cargar archivo shapefile\n",
    "mapa = gpd.read_file('../assets/states_500k.shp')\n",
    "\n",
    "# Calculamos los limites del mapa\n",
    "minx, miny, maxx, maxy = gdf.total_bounds\n",
    "\n",
    "# Creamos los plots del mapa\n",
    "\n",
    "plt.figure()  # clean up\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 9))\n",
    "mapa.plot(ax=ax, color='white', edgecolor='black')\n",
    "\n",
    "gdf = gdf[gdf.is_valid | gdf.buffer(0).is_valid]  # clean up\n",
    "\n",
    "gdf.plot(ax=ax, marker='o', color='red', markersize=.0001)\n",
    "\n",
    "# Calculamos el margen del grafico\n",
    "margin_ratio = 0.2\n",
    "marginx = (maxx - minx) * margin_ratio\n",
    "marginy = (maxy - miny) * margin_ratio\n",
    "# Aplicamos los margenes en relacion a los plots en los extremos\n",
    "ax.set_xlim(minx - marginx, maxx + marginx)\n",
    "ax.set_ylim(miny - marginy, maxy + marginy)\n",
    "\n",
    "plt.show()\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-pf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
