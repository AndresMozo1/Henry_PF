{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datasets a PostgreSQL\n",
    "Objetivo: disponibilidad de datos via web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_df_a_postgres(df: pd.DataFrame, nombre_tabla: str, uri_db: str, if_exists='replace') -> None:\n",
    "    \"\"\"Carga un archivo parquet a una nueva tabla en PostgreSQL,\n",
    "    si la tabla no exite. Si la tabla existe, el parquet se anexa.\n",
    "    \"\"\"\n",
    "    # Crear un motor de base de datos\n",
    "    engine = create_engine(uri_db)\n",
    "    # Anexar el dataframe a la tabla SQL\n",
    "    df.to_sql(nombre_tabla, engine, if_exists=if_exists, index=False)\n",
    "\n",
    "    # Cerrar la conexión\n",
    "    engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforms_de_compatibilidad(df: pd.DataFrame, nom_archivo: str) -> pd.DataFrame:\n",
    "    \"\"\"transforms_de_compatibilidad\n",
    "    \"\"\"\n",
    "    if nom_archivo == 'y_business':\n",
    "        df['attributes'] = df['attributes'].apply(json.dumps)\n",
    "        df['categories'] = df['categories'].apply(lambda x: str(x).split(',')).apply(json.dumps)\n",
    "        df['hours'] = df['hours'].apply(json.dumps)\n",
    "\n",
    "    elif nom_archivo == 'y_checkin':\n",
    "        df.set_index('business_id', inplace=True)\n",
    "        df['date'] = df['date'].str.split(',')\n",
    "        df = df.explode('date')\n",
    "        df['date'] = pd.to_datetime(df['date'], format='mixed')\n",
    "        df.reset_index(inplace=True)\n",
    "\n",
    "    elif nom_archivo == 'y_review':\n",
    "        pass\n",
    "\n",
    "    elif nom_archivo == 'y_user':\n",
    "        df['elite'] = df['elite'].apply(lambda x: str(x).split(',')).apply(lambda x: json.dumps(x) if x[0] else None)\n",
    "        df['friends'] = df['friends'].apply(lambda x: str(x).split(',')).apply(lambda x: json.dumps(x) if x[0] != \"None\" else None)\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    elif nom_archivo == 'y_tip':\n",
    "        pass\n",
    "\n",
    "    elif nom_archivo == 'g_sitios':\n",
    "        df['category'] = df['category'].apply(lambda x: json.dumps(x.tolist()) if x is not None else None)\n",
    "        df['hours'] =  df['hours'].apply((lambda x: json.dumps(dict(x.tolist())) if x is not None else None))\n",
    "        df['relative_results'] = df['relative_results'].apply(lambda x: json.dumps(x.tolist()) if x is not None else None)\n",
    "        df.drop('MISC', axis=1, inplace=True)\n",
    "        df.drop('url', axis=1, inplace=True)\n",
    "\n",
    "    elif nom_archivo == 'g_review':\n",
    "        df['time'] = pd.to_datetime(df['time'], unit='ms')\n",
    "        df['rating'] = df['rating'].astype('int16')\n",
    "        df['text'] = df['text'].apply(lambda x: x.replace('\\x00', ' ') if isinstance(x, str) else x)\n",
    "        df.drop('pics', axis=1, inplace=True)\n",
    "        df.drop('resp', axis=1, inplace=True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credenciales base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credenciales PostgreSQL\n",
    "db_user = 'henry'\n",
    "db_passwd = 'Onetwo12!'\n",
    "uri_base_datos = f'postgresql://{db_user}:{db_passwd}@localhost:5432/yelp_goog'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parquet únicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear lista de parquets en /data/raw/\n",
    "parquets_unicos = glob(f'../data/raw/*.parquet')\n",
    "parquets_unicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parquets_unicos:\n",
    "    nom_tabla = p.split('/')[-1].split('.')[0].replace('-','_')\n",
    "    print(f'Procesando {nom_tabla}')\n",
    "    df = pd.read_parquet(p)\n",
    "    cargar_df_a_postgres(transforms_de_compatibilidad(df, nom_tabla), nom_tabla, uri_base_datos)\n",
    "    print(f'{nom_tabla=} cargado a PostgreSQL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parquet fragmentados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/raw/g-review/g-review_California.parquet',\n",
       " '../data/raw/g-review/g-review_District_of_Columbia.parquet',\n",
       " '../data/raw/g-review/g-review_Florida.parquet',\n",
       " '../data/raw/g-review/g-review_Georgia.parquet',\n",
       " '../data/raw/g-review/g-review_Illinois.parquet',\n",
       " '../data/raw/g-review/g-review_New_Jersey.parquet',\n",
       " '../data/raw/g-review/g-review_New_York.parquet',\n",
       " '../data/raw/g-review/g-review_Pennsylvania.parquet',\n",
       " '../data/raw/g-review/g-review_Texas.parquet',\n",
       " '../data/raw/g-review/g-review_Virginia.parquet',\n",
       " '../data/raw/y-review/y-review_01.parquet',\n",
       " '../data/raw/y-review/y-review_02.parquet',\n",
       " '../data/raw/y-review/y-review_03.parquet',\n",
       " '../data/raw/y-user/y-user_01.parquet',\n",
       " '../data/raw/y-user/y-user_02.parquet',\n",
       " '../data/raw/y-user/y-user_03.parquet',\n",
       " '../data/raw/y-user/y-user_04.parquet']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear lista de parquets en /data/raw/*/\n",
    "parquets_frag = glob(f'../data/raw/*/*.parquet')\n",
    "parquets_frag.sort()\n",
    "parquets_frag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_review replace\n",
      "../data/raw/g-review/g-review_California.parquet\n",
      "cargado a nom_tabla='g_review' en PostgreSQL\n",
      "g_review append\n",
      "../data/raw/g-review/g-review_District_of_Columbia.parquet\n",
      "cargado a nom_tabla='g_review' en PostgreSQL\n",
      "g_review append\n",
      "../data/raw/g-review/g-review_Florida.parquet\n",
      "cargado a nom_tabla='g_review' en PostgreSQL\n",
      "g_review append\n",
      "../data/raw/g-review/g-review_Georgia.parquet\n",
      "cargado a nom_tabla='g_review' en PostgreSQL\n",
      "g_review append\n",
      "../data/raw/g-review/g-review_Illinois.parquet\n",
      "cargado a nom_tabla='g_review' en PostgreSQL\n",
      "g_review append\n",
      "../data/raw/g-review/g-review_New_Jersey.parquet\n",
      "cargado a nom_tabla='g_review' en PostgreSQL\n",
      "g_review append\n",
      "../data/raw/g-review/g-review_New_York.parquet\n",
      "cargado a nom_tabla='g_review' en PostgreSQL\n",
      "g_review append\n",
      "../data/raw/g-review/g-review_Pennsylvania.parquet\n",
      "cargado a nom_tabla='g_review' en PostgreSQL\n",
      "g_review append\n",
      "../data/raw/g-review/g-review_Texas.parquet\n",
      "cargado a nom_tabla='g_review' en PostgreSQL\n",
      "g_review append\n",
      "../data/raw/g-review/g-review_Virginia.parquet\n",
      "cargado a nom_tabla='g_review' en PostgreSQL\n"
     ]
    }
   ],
   "source": [
    "ultimo_nom_tabla = ''\n",
    "for p in parquets_frag:\n",
    "    nom_tabla = p.split('/')[-2].replace('-','_')\n",
    "    tipo_transaccion = 'append' if ultimo_nom_tabla == nom_tabla else 'replace'\n",
    "    print(nom_tabla, tipo_transaccion)\n",
    "    \n",
    "    df = pd.read_parquet(p)\n",
    "    cargar_df_a_postgres(transforms_de_compatibilidad(df, nom_tabla), nom_tabla, uri_base_datos, if_exists=tipo_transaccion)\n",
    "    print(f'{p}\\ncargado a {nom_tabla=} en PostgreSQL', end='\\n')\n",
    "\n",
    "    ultimo_nom_tabla = nom_tabla"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-pf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
