{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from ftfy import fix_text\n",
    "from geopy.distance import geodesic\n",
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz\n",
    "import carga_data as cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Yelp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../data/raw/y-business.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Path de los archivos no-procesados (formato parquet)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m path_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../data/raw\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m yelp \u001b[38;5;241m=\u001b[39m \u001b[43mcd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcargar_dataset_yelp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m yelp\u001b[38;5;241m.\u001b[39mkeys()\n",
      "File \u001b[1;32mc:\\Projects\\Henry_PF\\notebooks\\ETL\\carga_data.py:49\u001b[0m, in \u001b[0;36mcargar_dataset_yelp\u001b[1;34m(path_data)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Devuelve dict de dataframes del dataset\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;124;03mde Google Maps (un dataframe por tabla).\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Carga y-business.parquet\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m df_business \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpath_data\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/y-business.parquet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Carga y-checkin.parquet\u001b[39;00m\n\u001b[0;32m     51\u001b[0m df_checkin \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_data\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/y-checkin.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\seb\\miniconda3\\envs\\310\\lib\\site-packages\\pandas\\io\\parquet.py:667\u001b[0m, in \u001b[0;36mread_parquet\u001b[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[0;32m    664\u001b[0m     use_nullable_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    665\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[1;32m--> 667\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m impl\u001b[38;5;241m.\u001b[39mread(\n\u001b[0;32m    668\u001b[0m     path,\n\u001b[0;32m    669\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m    670\u001b[0m     filters\u001b[38;5;241m=\u001b[39mfilters,\n\u001b[0;32m    671\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    672\u001b[0m     use_nullable_dtypes\u001b[38;5;241m=\u001b[39muse_nullable_dtypes,\n\u001b[0;32m    673\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    674\u001b[0m     filesystem\u001b[38;5;241m=\u001b[39mfilesystem,\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    676\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\seb\\miniconda3\\envs\\310\\lib\\site-packages\\pandas\\io\\parquet.py:267\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[1;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    265\u001b[0m     to_pandas_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit_blocks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m path_or_handle, handles, filesystem \u001b[38;5;241m=\u001b[39m \u001b[43m_get_path_or_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    274\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mparquet\u001b[38;5;241m.\u001b[39mread_table(\n\u001b[0;32m    275\u001b[0m         path_or_handle,\n\u001b[0;32m    276\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    280\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\seb\\miniconda3\\envs\\310\\lib\\site-packages\\pandas\\io\\parquet.py:140\u001b[0m, in \u001b[0;36m_get_path_or_handle\u001b[1;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[0;32m    130\u001b[0m handles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m fs\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dir\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[1;32m--> 140\u001b[0m     handles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m     fs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    144\u001b[0m     path_or_handle \u001b[38;5;241m=\u001b[39m handles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\seb\\miniconda3\\envs\\310\\lib\\site-packages\\pandas\\io\\common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../data/raw/y-business.parquet'"
     ]
    }
   ],
   "source": [
    "# Path de los archivos no-procesados (formato parquet)\n",
    "path_data = '../../data/raw'\n",
    "yelp = cd.cargar_dataset_yelp(path_data)\n",
    "yelp.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_business, df_checkin, df_tip, df_review, df_user = yelp.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabla `business`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir columna 'categories' a tipo list\n",
    "df_business['categories'] = df_business['categories'].apply(lambda x: x.strip().replace(', ',',').split(',') if x else [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtro generales, basado en enfoque del proyecto (restaurantes dentro de una area geografica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10203, 13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Filtros principales del dataset\n",
    "#  Toda otra tabla del dataset se filtra en base a los \n",
    "#  `business_id` que se encuentran en el `df_business` procesado.\n",
    "\n",
    "# Filtrar donde `is_open == 1`\n",
    "df_business = df_business[df_business['is_open'] == 1]\n",
    "# Descartar col `is_open`\n",
    "df_business.drop('is_open', axis=1, inplace=True)\n",
    "\n",
    "# Filtrar por categoría 'Restaurants'\n",
    "filtro_categoria = 'Restaurants'\n",
    "df_business = df_business[df_business['categories'].apply(lambda x: filtro_categoria in x)]\n",
    "\n",
    "# Filtrar por estados de interes\n",
    "filtro_estado = ['DE', 'NJ', 'PA']\n",
    "df_business = df_business[df_business['state'].isin(filtro_estado)]\n",
    "\n",
    "df_business.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtro por coordinadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def es_dentro_de_area(latitude, longitude, punto_centro, radio=200) -> bool:\n",
    "    \"\"\"Devuelve valor boolean, True si `latitude` y `longitude` de entrada estan\n",
    "    dentro del area definido por `punto_centro` y `radio. De lo contrario,\n",
    "    devuelve False.\n",
    "    \"\"\"\n",
    "    # Calcular la distancia desde el punto central `punto_centro`\n",
    "    distancia = geodesic((latitude, longitude), punto_centro).miles\n",
    "    # Check if the distance is within the specified radius\n",
    "    return distancia <= radio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordinadas de Philadelphia, PA\n",
    "coord_philadelphia = (39.9526, -75.1652)\n",
    "\n",
    "# Crear nuava columna con \n",
    "df_business['es_dentro_de_area'] = df_business.apply(lambda x: es_dentro_de_area(x['latitude'], x['longitude'], coord_philadelphia), axis=1)\n",
    "\n",
    "df_business = df_business[df_business['es_dentro_de_area']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuevas columnas y tablas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un dataframe nuevo para los atributos\n",
    "df_attributes = df_business[['business_id', 'name', 'attributes']]\n",
    "# Descartar col `attributes`\n",
    "df_business.drop('attributes', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear nueva columna de coordinadas\n",
    "df_business['coordinates'] = df_business['latitude'].astype(str) + ',' + df_business['longitude'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabla `checkin`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10059, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtrar por `business_id` en el `df_business` procesado\n",
    "filtro_id = df_business['business_id']\n",
    "df_checkin = df_checkin[df_checkin['business_id'].isin(filtro_id)]\n",
    "df_checkin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir col `date` a tipo list\n",
    "df_checkin['date'] = df_checkin['date'].apply(lambda x: x.strip().replace(', ',',').split(',') if x else [])\n",
    "# Convertir items en listas de col `date` a tipo datetime \n",
    "df_checkin['date'] = df_checkin['date'].apply(lambda x: [pd.to_datetime(string, format='mixed') for string in x] if x else x) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabla `tip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar por `'business_id'` en el `df_business` procesado\n",
    "filtro_id = df_business[\"business_id\"]\n",
    "df_tip = df_tip[df_tip[\"business_id\"].isin(filtro_id)]\n",
    "df_tip.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabla `review`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1138498, 9)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtrar por `'business_id'` en el `df_business` procesado\n",
    "filtro_id = df_business[\"business_id\"]\n",
    "df_review = df_review[df_review[\"business_id\"].isin(filtro_id)]\n",
    "df_review.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transformaciones\n",
    "\n",
    "# Convertir col `date` a tipo datetime\n",
    "df_review['date'] = pd.to_datetime(df_review['date'], format='mixed')\n",
    "\n",
    "# Corrigir errores de decoding de texto, columna `text`\n",
    "df_review['text'] = df_review['text'].apply(fix_text)\n",
    "\n",
    "# Agregar col `name`, desde `df_business`\n",
    "df_review = pd.merge(df_review, df_business[['business_id', 'name']], on='business_id', how='left')\n",
    "# Fijar nueva columna `name` como la primer columna del df \n",
    "nom_col = df_review.pop('name')\n",
    "df_review.insert(0, 'name', nom_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabla `user`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar por `'user_id'` en el `df_review` procesado\n",
    "filtro_id = df_review['user_id']\n",
    "df_user = df_user[df_user['user_id'].isin(filtro_id)]\n",
    "df_user.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transformaciones\n",
    "\n",
    "# Convertir col `yelping_since` a tipo datetime\n",
    "df_user['yelping_since'] = pd.to_datetime(df_user['yelping_since'], format='mixed')\n",
    "\n",
    "# Convertir columna 'friends' a tipo list\n",
    "df_user['friends'] = df_user['friends'].apply(lambda x: x.replace(', ',',').split(',') if x != 'None' else [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exportaciones data procesada Yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Almacenar dataframes en formato parquet\n",
    "\n",
    "# Path de los archivos procesados (formato parquet)\n",
    "path_data_clean = '../../data/clean'\n",
    "\n",
    "df_business.to_parquet(f'{path_data_clean}/y_business_CLEAN.parquet')\n",
    "df_attributes.to_parquet(f'{path_data_clean}/y_attributes_CLEAN.parquet')\n",
    "df_checkin.to_parquet(f'{path_data_clean}/y_checkin_CLEAN.parquet')\n",
    "df_tip.to_parquet(f'{path_data_clean}/y_tip_CLEAN.parquet')\n",
    "df_review.to_parquet(f'{path_data_clean}/y_review_CLEAN.parquet')\n",
    "df_user.to_parquet(f'{path_data_clean}/y_user_CLEAN.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liberar memoria, eliminando las variables de dataframes\n",
    "del yelp\n",
    "del df_business\n",
    "del df_checkin\n",
    "del df_tip\n",
    "del df_review\n",
    "del df_user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Google"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path de los archivos no-procesados (formato parquet)\n",
    "path_data = '../../data/raw'\n",
    "goog = cd.cargar_dataset_google(path_data)\n",
    "goog.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sitios, df_review = goog.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tambien se carga la tabla `business` del dataset de Yelp para facilitar el filtrado de `df_sitios`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path de los archivos procesados (formato parquet)\n",
    "path_data_clean = '../../data/clean'\n",
    "df_yelp_business = pd.read_parquet(f'{path_data_clean}/y_business_CLEAN.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrado de validacion cruzada con Yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion que implementa busqueda 'fuzzy' en textos\n",
    "def fuzzy_match(x, match_to, threshold=90):\n",
    "    match, score, _ = process.extractOne(x, match_to, scorer=fuzz.WRatio)\n",
    "    return match if score >= threshold else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exportaciones data procesada Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Almacenar dataframes en formato parquet\n",
    "\n",
    "# Path de los archivos procesados (formato parquet)\n",
    "path_data = '../../data/clean'\n",
    "\n",
    "df_sitios.to_parquet(f'{path_data}/g_sitios_CLEAN.parquet')\n",
    "df_review.to_parquet(f'{path_data}/g_reviews_CLEAN.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liberar memoria, eliminando las variables de dataframes\n",
    "del goog\n",
    "del df_sitios\n",
    "del df_review"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-pf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
