{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test de LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba de uso de modelos LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe ejemplar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opci√≥n que deshabilita el limite de columnas y filas mostradas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('y_review_CLEAN.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['name', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.sample(400)\n",
    "#df.to_csv('review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>respuesta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>752010</th>\n",
       "      <td>Provisions Coffee &amp; Kitchen</td>\n",
       "      <td>Great place to go for breakfast, brunch, lunch...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091914</th>\n",
       "      <td>Misconduct Tavern</td>\n",
       "      <td>I've heard lots about Misconduct. It's half-of...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157531</th>\n",
       "      <td>Flamingo A-Go-Go</td>\n",
       "      <td>I love this place when it's packed. When it's ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150482</th>\n",
       "      <td>St. Louis Fish &amp; Chicken Grill</td>\n",
       "      <td>Great prices. Love the food, especially the Ph...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766153</th>\n",
       "      <td>Edley's Bar-B-Que - 12 South</td>\n",
       "      <td>Road Trip 2016 - a wonderful ten days that wou...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386131</th>\n",
       "      <td>Stingray's Grill &amp; Bar</td>\n",
       "      <td>We came to try the \"All you can eat Snow Crabs...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653742</th>\n",
       "      <td>Antoine's Restaurant</td>\n",
       "      <td>Dinner at Antoine's was a major highlight of m...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995125</th>\n",
       "      <td>Seiko Japanese Restaurant</td>\n",
       "      <td>This has got to be the greatest sushi place of...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868848</th>\n",
       "      <td>Parc</td>\n",
       "      <td>Very high quality food and good drinks. I must...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354410</th>\n",
       "      <td>Biscuit Love: Gulch</td>\n",
       "      <td>I had high expectations of this place and it d...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   name  \\\n",
       "752010      Provisions Coffee & Kitchen   \n",
       "1091914               Misconduct Tavern   \n",
       "157531                 Flamingo A-Go-Go   \n",
       "150482   St. Louis Fish & Chicken Grill   \n",
       "766153     Edley's Bar-B-Que - 12 South   \n",
       "386131           Stingray's Grill & Bar   \n",
       "653742             Antoine's Restaurant   \n",
       "995125        Seiko Japanese Restaurant   \n",
       "868848                             Parc   \n",
       "354410              Biscuit Love: Gulch   \n",
       "\n",
       "                                                      text respuesta  \n",
       "752010   Great place to go for breakfast, brunch, lunch...      None  \n",
       "1091914  I've heard lots about Misconduct. It's half-of...      None  \n",
       "157531   I love this place when it's packed. When it's ...      None  \n",
       "150482   Great prices. Love the food, especially the Ph...      None  \n",
       "766153   Road Trip 2016 - a wonderful ten days that wou...      None  \n",
       "386131   We came to try the \"All you can eat Snow Crabs...      None  \n",
       "653742   Dinner at Antoine's was a major highlight of m...      None  \n",
       "995125   This has got to be the greatest sushi place of...      None  \n",
       "868848   Very high quality food and good drinks. I must...      None  \n",
       "354410   I had high expectations of this place and it d...      None  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(10)\n",
    "df['respuesta'] = None\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'].to_csv('1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### version Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from ctransformers import AutoModelForCausalLM\n",
    "\n",
    "model_Q5 = AutoModelForCausalLM.from_pretrained(\"TheBloke/Mistral-7B-OpenOrca-GGUF\", \n",
    "                                           model_file=\"mistral-7b-openorca.Q5_K_M.gguf\",\n",
    "                                           model_type=\"mistral\",\n",
    "                                           gpu_layers=0\n",
    "                                           )\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctransformers import AutoModelForCausalLM\n",
    "\n",
    "def get_model():\n",
    "    model_Q5 = AutoModelForCausalLM.from_pretrained(\"TheBloke/Mistral-7B-OpenOrca-GGUF\", \n",
    "                                           model_file=\"mistral-7b-openorca.Q5_K_M.gguf\",\n",
    "                                           model_type=\"mistral\",\n",
    "                                           gpu_layers=0\n",
    "                                           )\n",
    "    return model_Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_respuesta_Q5(review: str) -> str:\n",
    "    prompt = f\"\"\"You are a humble restaurant manager that uses casual language. \n",
    "    You never give an explanation regarding the text you output. \n",
    "    Write a very short one sentence reply to the customer regarding this review: {review}\n",
    "    \"\"\"\n",
    "    model_Q5 = get_model()\n",
    "    return model_Q5(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar respuestas en nueva columna\n",
    "df['respuesta'] = df['text'].apply(lambda x: generar_respuesta_Q5(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimir resultados\n",
    "for i in df.index:\n",
    "    print(f\"Review: {df['text'][i]}\\nReply: {df['respuesta'][i]}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### version Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctransformers import AutoModelForCausalLM\n",
    "\n",
    "model_Q4 = AutoModelForCausalLM.from_pretrained(\"TheBloke/Mistral-7B-OpenOrca-GGUF\", \n",
    "                                           model_file=\"mistral-7b-openorca.Q4_K_M.gguf\",\n",
    "                                           model_type=\"mistral\",\n",
    "                                           gpu_layers=0\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_respuesta_Q4(review: str) -> str:\n",
    "    prompt = f\"\"\"You are a humble restaurant manager that uses casual language. \n",
    "    You never give an explanation regarding the text you output. \n",
    "    Write a very short one sentence reply to the customer regarding this review: {review}\n",
    "    \"\"\"\n",
    "    return model_Q4(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar respuestas en nueva columna\n",
    "df['respuesta'] = df['reviews'].apply(generar_respuesta_Q4)\n",
    "\n",
    "# Imprimir resultados\n",
    "for i in df.index:\n",
    "    print(f\"{df['reviews'][i] = }\\n{df['respuesta'][i] = }\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### version Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctransformers import AutoModelForCausalLM\n",
    "\n",
    "model_Q2 = AutoModelForCausalLM.from_pretrained(\"TheBloke/Mistral-7B-OpenOrca-GGUF\", \n",
    "                                           model_file=\"mistral-7b-openorca.Q2_K.gguf\",\n",
    "                                           model_type=\"mistral\",\n",
    "                                           gpu_layers=0\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_respuesta_Q2(review: str) -> str:\n",
    "    prompt = f\"\"\"You are a humble restaurant manager that uses casual language. \n",
    "    You never give an explanation regarding the text you output. \n",
    "    Write a very short one sentence reply to the customer regarding this review: {review}\n",
    "    \"\"\"\n",
    "    return model_Q2(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar respuestas en nueva columna\n",
    "df['respuesta'] = df['reviews'].apply(generar_respuesta_Q2)\n",
    "\n",
    "# Imprimir resultados\n",
    "for i in df.index:\n",
    "    print(f\"{df['reviews'][i] = }\\n{df['respuesta'][i] = }\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-pf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
