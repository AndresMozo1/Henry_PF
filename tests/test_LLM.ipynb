{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test de LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba de uso de modelos LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe ejemplar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opci√≥n que deshabilita el limite de columnas y filas mostradas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('y_review_CLEAN.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['name', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.sample(400)\n",
    "#df.to_csv('review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>respuesta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>633476</th>\n",
       "      <td>Hunan Empress</td>\n",
       "      <td>I can't comment on their other food (probably ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name                                               text  \\\n",
       "633476  Hunan Empress  I can't comment on their other food (probably ...   \n",
       "\n",
       "       respuesta  \n",
       "633476      None  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(1)\n",
    "df['respuesta'] = None\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### version Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from ctransformers import AutoModelForCausalLM\n",
    "\n",
    "model_Q5 = AutoModelForCausalLM.from_pretrained(\"TheBloke/Mistral-7B-OpenOrca-GGUF\", \n",
    "                                           model_file=\"mistral-7b-openorca.Q5_K_M.gguf\",\n",
    "                                           model_type=\"mistral\",\n",
    "                                           gpu_layers=0\n",
    "                                           )\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctransformers import AutoModelForCausalLM\n",
    "\n",
    "def get_model():\n",
    "    model_Q5 = AutoModelForCausalLM.from_pretrained(\"TheBloke/Mistral-7B-OpenOrca-GGUF\", \n",
    "                                           model_file=\"mistral-7b-openorca.Q5_K_M.gguf\",\n",
    "                                           model_type=\"mistral\",\n",
    "                                           gpu_layers=0\n",
    "                                           )\n",
    "    return model_Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_respuesta_Q5(review: str) -> str:\n",
    "    prompt = f\"\"\"You are a humble restaurant manager that uses casual language. \n",
    "    The context is you are talking to a customer. \n",
    "    Write a very short one sentence replying to the customer about this review they wrote: {review}\n",
    "    \"\"\"\n",
    "    model_Q5 = get_model()\n",
    "    return model_Q5(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ff232f2caa84dfc971a059125e75ab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ed2d7ec98bd40d68ea5771dd185b630",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generar respuestas en nueva columna\n",
    "df['respuesta'] = df['text'].apply(generar_respuesta_Q5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: I can't comment on their other food (probably average), but I have to say that the fried rice is absolutely terrible here and in west county in general. I repeat, this review is for the the FRIED RICE ONLY. I don't know if it's a different kind of rice, or is cooked differently, but it ends up disgustingly flavorless/dry/sponge-like and no amount of soy sauce will fix it. I love fried rice and I'm the kind to eat every last grain of rice on my plate, and with this place I ended up picking the meat out and wasting more than half the rice.\n",
      "\n",
      "The best fried rice I've ever had was Golden China in the valley, but they closed (should have never switched locations). Second best was North Hunan in North County, but they closed a long time ago. Panda would be a couple notches below them, but is way out in Kirkwood. A notch below Panda I'd put China Wok (North County) and Rice House (Florissant), followed by China Garden (141 & Clayton). WAY below them is Wok Express (Maryland Heights), then Hunan Empress and Summer Palace. I've had Zang Chi once and I don't remember it being much better than Hunan Empress and Summer Palace.\n",
      "\n",
      "I'm definitely open to suggestions if anyone else feels the same way as me and knows where to get some fried rice that is actually moist and tasty.\n",
      "Reply: \n",
      "Thank you for your review! We appreciate any feedback from our customers, especially when it helps us improve. Based on your experience with our fried rice, we'll make sure to take note of it and work on making it better. It's great to know that there are many places out there that serve good fried rice too, and I can understand why you would be disappointed if ours doesn't meet your standards. Please feel free to come back and try our other dishes, as we believe there is still a chance for you to find something delicious in our menu. We hope to see you soon and serve you better!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imprimir resultados\n",
    "for i in df.index:\n",
    "    print(f\"Review: {df['text'][i]}\\nReply: {df['respuesta'][i]}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### version Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctransformers import AutoModelForCausalLM\n",
    "\n",
    "model_Q4 = AutoModelForCausalLM.from_pretrained(\"TheBloke/Mistral-7B-OpenOrca-GGUF\", \n",
    "                                           model_file=\"mistral-7b-openorca.Q4_K_M.gguf\",\n",
    "                                           model_type=\"mistral\",\n",
    "                                           gpu_layers=0\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_respuesta_Q4(review: str) -> str:\n",
    "    prompt = f\"\"\"You are a humble restaurant manager that uses casual language. \n",
    "    You never give an explanation regarding the text you output. \n",
    "    Write a very short one sentence reply to the customer regarding this review: {review}\n",
    "    \"\"\"\n",
    "    return model_Q4(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar respuestas en nueva columna\n",
    "df['respuesta'] = df['reviews'].apply(generar_respuesta_Q4)\n",
    "\n",
    "# Imprimir resultados\n",
    "for i in df.index:\n",
    "    print(f\"{df['reviews'][i] = }\\n{df['respuesta'][i] = }\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### version Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctransformers import AutoModelForCausalLM\n",
    "\n",
    "model_Q2 = AutoModelForCausalLM.from_pretrained(\"TheBloke/Mistral-7B-OpenOrca-GGUF\", \n",
    "                                           model_file=\"mistral-7b-openorca.Q2_K.gguf\",\n",
    "                                           model_type=\"mistral\",\n",
    "                                           gpu_layers=0\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_respuesta_Q2(review: str) -> str:\n",
    "    prompt = f\"\"\"You are a humble restaurant manager that uses casual language. \n",
    "    You never give an explanation regarding the text you output. \n",
    "    Write a very short one sentence reply to the customer regarding this review: {review}\n",
    "    \"\"\"\n",
    "    return model_Q2(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar respuestas en nueva columna\n",
    "df['respuesta'] = df['reviews'].apply(generar_respuesta_Q2)\n",
    "\n",
    "# Imprimir resultados\n",
    "for i in df.index:\n",
    "    print(f\"{df['reviews'][i] = }\\n{df['respuesta'][i] = }\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-pf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
