{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test de LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba de uso de modelos LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe ejemplar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample dataframe\n",
    "df = pd.DataFrame({\n",
    "    'reviews': [\n",
    "        \"I loved the quick service and friendly staff!\",\n",
    "        \"The food did not meet my expectations.\"\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### version Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e011669901449d4a146b5e4770cbefc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f4aede14d4540d6a83f83bc44c7b9b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ctransformers import AutoModelForCausalLM\n",
    "\n",
    "model_Q5 = AutoModelForCausalLM.from_pretrained(\"TheBloke/Mistral-7B-OpenOrca-GGUF\", \n",
    "                                           model_file=\"mistral-7b-openorca.Q5_K_M.gguf\",\n",
    "                                           model_type=\"mistral\",\n",
    "                                           gpu_layers=0\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt = f\"\"\"You are an restaurant manager that uses casual language and does not explain your reply. \n",
    "#Write a one sentence casual reply to the customer regarding this review: {review}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_respuesta_Q5(review: str) -> str:\n",
    "    prompt = f\"\"\"You are an empathetic restaurant manager that uses casual language and does not explain your reply. \n",
    "    Write a one sentence casual reply to the customer regarding this review: {review}\n",
    "    \"\"\"\n",
    "    return model_Q5(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df['reviews'][i] = 'I loved the quick service and friendly staff!'\n",
      "df['respuesta'][i] = '\\n    \"We\\'re glad you enjoyed our fast service and friendly workers, thanks for stopping by!\"'\n",
      "\n",
      "\n",
      "df['reviews'][i] = 'The food did not meet my expectations.'\n",
      "df['respuesta'][i] = '\\n    \"I\\'m sorry to hear you didn\\'t enjoy the meal, we strive for excellence in all our dishes and will make sure to look into this issue with the team to provide an even better experience next time.\"'\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generar respuestas en nueva columna\n",
    "df['respuesta'] = df['reviews'].apply(generar_respuesta_Q5)\n",
    "\n",
    "# Imprimir resultados\n",
    "for i in df.index:\n",
    "    print(f\"{df['reviews'][i] = }\\n{df['respuesta'][i] = }\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### version Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "196a8834faef47e3a2b418be18e17fa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98a6daba0f694f86807a969cc27c30a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ctransformers import AutoModelForCausalLM\n",
    "\n",
    "model_Q4 = AutoModelForCausalLM.from_pretrained(\"TheBloke/Mistral-7B-OpenOrca-GGUF\", \n",
    "                                           model_file=\"mistral-7b-openorca.Q4_K_M.gguf\",\n",
    "                                           model_type=\"mistral\",\n",
    "                                           gpu_layers=0\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_respuesta_Q4(review: str) -> str:\n",
    "    prompt = f\"\"\"You are an empathetic restaurant manager that uses casual language and does not explain your reply. \n",
    "    Write a one sentence casual reply to the customer regarding this review: {review}\n",
    "    \"\"\"\n",
    "    return model_Q4(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df['reviews'][i] = 'I loved the quick service and friendly staff!'\n",
      "df['respuesta'][i] = '\\n   \"Hey there, thanks so much for coming in and loving our speedy service and awesome team! We\\'re always working on making things even better for our guests. Your feedback is super important to us!\"'\n",
      "\n",
      "\n",
      "df['reviews'][i] = 'The food did not meet my expectations.'\n",
      "df['respuesta'][i] = '\\nReply: \"I\\'m sorry you didn\\'t have a good experience, I will let the chef know about your feedback.\"'\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generar respuestas en nueva columna\n",
    "df['respuesta'] = df['reviews'].apply(generar_respuesta_Q4)\n",
    "\n",
    "# Imprimir resultados\n",
    "for i in df.index:\n",
    "    print(f\"{df['reviews'][i] = }\\n{df['respuesta'][i] = }\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### version Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aa118216603494189d47c43378a2cf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7848b251b3424521915264ff012a0b5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ctransformers import AutoModelForCausalLM\n",
    "\n",
    "model_Q2 = AutoModelForCausalLM.from_pretrained(\"TheBloke/Mistral-7B-OpenOrca-GGUF\", \n",
    "                                           model_file=\"mistral-7b-openorca.Q2_K.gguf\",\n",
    "                                           model_type=\"mistral\",\n",
    "                                           gpu_layers=0\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_respuesta_Q2(review: str) -> str:\n",
    "    prompt = f\"\"\"You are an empathetic restaurant manager that uses casual language and does not explain your reply. \n",
    "    Write a one sentence casual reply to the customer regarding this review: {review}\n",
    "    \"\"\"\n",
    "    return model_Q2(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df['reviews'][i] = 'I loved the quick service and friendly staff!'\n",
      "df['respuesta'][i] = '\\n     \"Awesome, glad you enjoyed the fast service and friendly crew!\"'\n",
      "\n",
      "\n",
      "df['reviews'][i] = 'The food did not meet my expectations.'\n",
      "df['respuesta'][i] = '\\nCasual Reply: \"Sorry to hear that! Would you mind sharing more about what you were expecting so we can address the situation? ðŸ˜ƒ\"'\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generar respuestas en nueva columna\n",
    "df['respuesta'] = df['reviews'].apply(generar_respuesta_Q2)\n",
    "\n",
    "# Imprimir resultados\n",
    "for i in df.index:\n",
    "    print(f\"{df['reviews'][i] = }\\n{df['respuesta'][i] = }\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-pf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
