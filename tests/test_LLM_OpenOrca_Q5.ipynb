{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test de LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba de uso de modelos LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Opción que deshabilita el limite de columnas y filas mostradas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = '../data/clean'\n",
    "df = pd.read_parquet(f'{path_data}/reviews_darden.parquet')\n",
    "df = df[['name', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar muestra\n",
    "df = df.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### version Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15b66111f71c48368d9a90ad1c7667f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c28ba4e09f84ec9be7e03a32e9208d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ctransformers import AutoModelForCausalLM\n",
    "\n",
    "model_Q5 = AutoModelForCausalLM.from_pretrained(\"TheBloke/Mistral-7B-OpenOrca-GGUF\", \n",
    "                                        model_file=\"mistral-7b-openorca.Q5_K_M.gguf\",\n",
    "                                        model_type=\"mistral\",\n",
    "                                        max_new_tokens=128,\n",
    "                                        reset=True,\n",
    "                                        gpu_layers=0\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(review):\n",
    "    prompt = f\"\"\"\n",
    "    You are a humble restaurant manager that uses casual language. \n",
    "    You are talking to a customer. Do not call customer by their name. \n",
    "    With a short one sentence, reply to this Yelp review posted by the customer: \n",
    "    {review}\n",
    "    \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ">>> Review:\n",
      "Always love Bahamas Breeze!!! Great service and great burgers\n",
      "I've been many times. The drinks are excellent. Friendly staff. Had my 65th Birthday party there.\n",
      "\n",
      ">>> Reply: \n",
      "\n",
      "    Reply: \"Thank you for your kind words! We're always happy to hear that our guests enjoy their time at Bahamas Breeze. Can't wait to host your next celebration with us!\"\n",
      "\n",
      ">>> Review:\n",
      "One of my favorite restaurants! You can never go wrong here! The price is reasonable as the food is so fresh and delicious! Staff is always do well mannered and accommodating.\n",
      "\n",
      "The flat breads are to die for! One of my favorites being the four mushroom which is not seasonal so\n",
      "You can always get it! So if you like goat cheese and mushrooms I would say to get that! Their lobster bisque is also a favorite!\n",
      "\n",
      "As for their desserts, i love that they come in almost a shot glass? It's small, personal, and the perfect amount after a tasty meal! Right now they have a pumpkin one and it's so good! \n",
      "\n",
      "Lastly, they also have an expansive drink menu!\n",
      "\n",
      ">>> Reply: \n",
      "\n",
      "    \"Thanks for your kind words! We're happy you enjoy our food and hospitality. Come back anytime!\""
     ]
    }
   ],
   "source": [
    "reviews = df['text'].tolist()\n",
    "\n",
    "for review in reviews:\n",
    "    print(f'\\n\\n>> Review:\\n{review}\\n\\n>> Reply: ')\n",
    "\n",
    "    for text in model_Q5(get_prompt(review), stream=True):\n",
    "        print(text, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba de prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Here's your response:\n",
      "\n",
      "\"Estamos lamentablemente conscientes de la experiencia desapointante que tuviste. Estaremos trabajando duro para mejorar nuestros platillos y ofrecer un ambiente más agradable en el futuro. Que tengas una buenos dias.\"\n",
      "\n",
      "Translation:\n",
      "\"We are unfortunately aware of the disappointing experience you had. We will be working hard to improve our dishes and offer a more pleasant atmosphere in the future. Have a good day.\""
     ]
    }
   ],
   "source": [
    "test_review = \"Comida mala, no vuelvo.\"\n",
    "\n",
    "test_prompt = f'''\n",
    "You are a humble restaurant manager. \n",
    "You are talking to a Yelp user in their language. \n",
    "With a short one sentence reply to this Yelp review posted by the user: \n",
    "\"{test_review}\"\n",
    "'''\n",
    "\n",
    "for text in model_Q5(test_prompt, stream=True):\n",
    "    print(text, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-pf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
